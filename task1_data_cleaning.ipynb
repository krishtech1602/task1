{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce80ce91",
   "metadata": {},
   "source": [
    "# ðŸ§¹ Task 1: Data Cleaning & Preprocessing\n",
    "This notebook covers:\n",
    "- Importing and exploring the dataset\n",
    "- Handling missing values\n",
    "- Encoding categorical features\n",
    "- Normalizing/standardizing numerical features\n",
    "- Detecting and removing outliers\n",
    "\n",
    "Dataset: Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7991ff8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3575295231.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    from scikit-learn.preprocessing import StandardScaler, MinMaxScaler\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scikit-learn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Show all columns in pandas\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Load the dataset (download from Kaggle if not available)\n",
    " #Link: ://www.kaggle.com/dhttpsatasets/yasserh/titanic-dataset\n",
    "# Make sure to keep 'titanic.csv' in the same folder as this notebook\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdec216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Basic Info about Dataset\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df391ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Handle Missing Values\n",
    "\n",
    "# Fill missing 'Age' with median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing 'Embarked' with mode\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop 'Cabin' due to too many missing values\n",
    "df.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Encode Categorical Variables\n",
    "\n",
    "# One-Hot Encoding for 'Sex' and 'Embarked'\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Normalize/Standardize Numerical Columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Age', 'Fare']\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Outlier Detection using Boxplot\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i, col in enumerate(numerical_features, 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Remove Outliers using IQR Method\n",
    "\n",
    "for col in numerical_features:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "print(\"Shape after removing outliers:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b560b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9: Save Cleaned Dataset\n",
    "df.to_csv(\"titanic_cleaned.csv\", index=False)\n",
    "print(\"âœ… Cleaned dataset saved as 'titanic_cleaned.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
